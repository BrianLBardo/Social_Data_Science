{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word embeddings i Python\n",
    "\n",
    "I denne notebook vises, hvordan man kan arbejde med word embeddings i Python.\n",
    "\n",
    "Der vises først, hvordan man kan tilgå trænede embeddings/vectors fra sprogmodellerne fra `spaCy`. Derefter vises, hvordan man kan arbejde med trænede embeddings/vectors fra `gensim` ([https://radimrehurek.com/gensim/](https://radimrehurek.com/gensim/))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indlæser pakker\n",
    "import pandas as pd\n",
    "\n",
    "# spacy\n",
    "import spacy\n",
    "\n",
    "# gensim\n",
    "from gensim.models import Word2Vec # word2vec model\n",
    "import gensim.downloader # download funktion til at hente eksisterende modeller/vectors med gensim\n",
    "\n",
    "\n",
    "# indlæs sprogmodel\n",
    "nlp = spacy.load('da_core_news_md')\n",
    "nlp_en = spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brug af præ-trænede embeddings/vectors i `spaCy`\n",
    "\n",
    "`spaCy` bruger word embeddings til bedre at kunne prædiktere andre attributter af et tekststykke (fx part-of-speech, dependency parsing og named entity recognition).\n",
    "\n",
    "Man kan tilgå de trænede embeddings for et ord ved blot at køre det igennem et `spaCy` pipeline (`nlp`) og tilgå visse attributter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp(\"danmark\").vector # vector repræsentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp(\"danmark\").vector.shape # antal dimensioner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sammenlign enkelte ord i modellen\n",
    "\n",
    "Lighed mellem vektorer kan måles med metoden `similarity()` for et `doc` objekt (et stykke tekst kørt igennem pipeline - `nlp()`). Angiver lighed som cosinus lighed (\"cosine similarity\").\n",
    "\n",
    "I det nedenstående sammenlignes embeddings for 'sverige', 'tyskland' og 'danmark'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sverige = nlp('sverige')\n",
    "tyskland = nlp('tyskland')\n",
    "danmark = nlp('danmark')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lighed mellem ord**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6354022937741272"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sverige.similarity(tyskland)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6236296901809797"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "danmark.similarity(tyskland)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6780375257368823"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "danmark.similarity(sverige)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Engelsk**\n",
    "\n",
    "Herunder gøres det samme, men for engelsk. Bemærk forskellen i lighed - hvordan kan det være?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweden = nlp_en('sweden')\n",
    "germany = nlp_en('germany')\n",
    "denmark = nlp_en('denmark')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6387296802300224"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sweden.similarity(germany)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6248384332660103"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "denmark.similarity(germany)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8716510217277486"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "denmark.similarity(sweden)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dokument ligheder**\n",
    "\n",
    "Man kan også måle lighed mellem hele tekststykker. Cosine similarity udregnes ud fra gennemsnit af de enkelte ord vektorer i tekststykket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1 = nlp(\"Jeg kan lide bananer\")\n",
    "doc2 = nlp(\"Jeg kommer fra Tyskland\")\n",
    "doc3 = nlp(\"Jeg bor i Danmark\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4283175755531724"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc1.similarity(doc2) # hvor meget ligner doc1 doc2?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6080683137095485"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc2.similarity(doc3) # hvor meget ligner doc2 doc3?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brug af præ-trænede embeddings/vectors med `gensim`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Download præ-trænet model**\n",
    "\n",
    "`gensim` har en række modeller, som kan hentes direkte gennem pakken (engelske modeller):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fasttext-wiki-news-subwords-300',\n",
       " 'conceptnet-numberbatch-17-06-300',\n",
       " 'word2vec-ruscorpora-300',\n",
       " 'word2vec-google-news-300',\n",
       " 'glove-wiki-gigaword-50',\n",
       " 'glove-wiki-gigaword-100',\n",
       " 'glove-wiki-gigaword-200',\n",
       " 'glove-wiki-gigaword-300',\n",
       " 'glove-twitter-25',\n",
       " 'glove-twitter-50',\n",
       " 'glove-twitter-100',\n",
       " 'glove-twitter-200',\n",
       " '__testing_word2vec-matrix-synopsis']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(gensim.downloader.info()['models'].keys()) # liste over direkte tilgængelige modeller"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Man kan hente og indlæse de præ-trænede vectors i modellen med `gensim.downloader.load()` funktionen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 128.1/128.1MB downloaded\n"
     ]
    }
   ],
   "source": [
    "pretrained_vectors = gensim.downloader.load('glove-wiki-gigaword-100')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Brug af præ-trænet model i gensim**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.28875  , -0.19655  ,  0.26046  ,  0.086723 ,  0.25918  ,\n",
       "       -0.1897   , -0.54331  ,  0.009582 , -0.30836  , -0.0031624,\n",
       "        0.33199  , -0.29428  , -0.24047  ,  1.19     , -0.084937 ,\n",
       "        0.11623  , -0.21052  , -0.54361  , -0.99796  ,  0.12067  ,\n",
       "        0.14138  ,  0.65072  ,  1.2077   ,  1.1735   ,  0.23783  ,\n",
       "       -0.98251  ,  0.41053  ,  0.27652  ,  0.52805  , -0.48693  ,\n",
       "       -0.8589   ,  0.35657  ,  0.71596  ,  0.17604  ,  0.52895  ,\n",
       "       -0.2974   ,  0.44817  ,  0.40725  , -0.98995  , -0.90026  ,\n",
       "       -0.57812  ,  0.050827 ,  0.32352  ,  0.087861 , -0.023458 ,\n",
       "       -0.34776  ,  0.88943  ,  0.10766  ,  0.46515  , -0.20827  ,\n",
       "        0.59546  ,  0.16455  , -0.45227  ,  0.6851   , -0.87772  ,\n",
       "       -1.7848   , -0.37841  , -0.25611  ,  0.15408  ,  0.067509 ,\n",
       "        0.71967  , -0.31071  , -0.15901  , -0.066492 ,  0.50181  ,\n",
       "        0.99762  , -1.1725   ,  1.5181   ,  0.14916  , -0.11483  ,\n",
       "        0.072389 , -0.66993  ,  0.36882  ,  0.37702  ,  0.36758  ,\n",
       "        0.15591  , -0.10071  , -0.53873  , -0.35206  ,  0.60048  ,\n",
       "        0.31707  , -0.47386  ,  0.45003  ,  0.37695  , -0.38389  ,\n",
       "       -0.54477  , -0.28152  , -0.037618 ,  0.20349  , -0.28685  ,\n",
       "        0.083537 , -0.11225  ,  0.74851  , -0.047845 , -0.49077  ,\n",
       "        0.21637  , -0.65435  ,  0.428    ,  0.66858  , -1.0518   ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_vectors['denmark'] # vector for enkelt ord"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Find mest lignende ord**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('sweden', 0.8624401092529297),\n",
       " ('norway', 0.8288263082504272),\n",
       " ('netherlands', 0.8032277226448059),\n",
       " ('finland', 0.7628087401390076),\n",
       " ('austria', 0.7483422756195068),\n",
       " ('germany', 0.7414340376853943),\n",
       " ('belgium', 0.7279534935951233),\n",
       " ('hungary', 0.7076718807220459),\n",
       " ('luxembourg', 0.6797297596931458),\n",
       " ('switzerland', 0.6770632266998291)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_vectors.most_similar('denmark')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sammenlign specifikke ord**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7414341"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_vectors.similarity('denmark', 'germany')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8624401"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_vectors.similarity('denmark', 'sweden')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Vector algebra**\n",
    "\n",
    "Vectors fra `gensim` tillader \"vector algebra\" - altså en måde at lave udregninger baseret på word embeddings. \n",
    "\n",
    "Et klassisk eksempel på vector algebra med word embeddings er fx $king + woman - man = queen$. Denne udregning kan vi foretage med `gensim` via metoden `most_similar()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_vectors.most_similar(positive=['woman', 'cat'],  # *Man* is to *woman* as *cat* is to ... (woman + cat - man = ?)\n",
    "                                negative=['man'], \n",
    "                                topn=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_vectors.most_similar(positive=['king', 'woman'], # king + woman - man = ?\n",
    "                           negative=['man'], \n",
    "                           topn=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_vectors.most_similar(positive=['berlin', 'denmark'],  # berlin + danmark - germany = ?\n",
    "                           negative=['germany'], \n",
    "                           topn=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bias i modellen**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_vectors.most_similar(positive=['doctor', 'woman'], # doctor + woman - man = ?\n",
    "                           negative=['man'], \n",
    "                           topn=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_vectors.most_similar(positive=['manager', 'woman'],  # manager + woman - man = ?\n",
    "                           negative=['man'], \n",
    "                           topn=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2 (default, Feb 28 2021, 17:03:44) \n[GCC 10.2.1 20210110]"
  },
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
