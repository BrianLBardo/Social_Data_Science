{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word embeddings i Python\n",
    "\n",
    "I denne notebook vises, hvordan man kan træne sin egen word embeddings model med `gensim` i Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indlæser pakker\n",
    "import os\n",
    "from os.path import join\n",
    "import pandas as pd\n",
    "from tqdm import tqdm # progress bar\n",
    "\n",
    "# spacy\n",
    "import spacy\n",
    "\n",
    "# gensim\n",
    "from gensim.models import Word2Vec # word2vec model\n",
    "import gensim.downloader # download funktion til at hente eksisterende modeller/vectors med gensim\n",
    "\n",
    "\n",
    "# indlæs sprogmodel\n",
    "nlp = spacy.load('da_core_news_md')\n",
    "nlp_en = spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Træn din egen model\n",
    "\n",
    "Vi træner her en word embeddings model med referater for møder i Folketinget.\n",
    "\n",
    "Først skal data indlæses og sættes i korrekt format - `gensim` forventer input i form af en *liste med lister af tokens* - en liste af tokens per tekst."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Indlæs og sæt data i korrekt format**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_p = join('/work', '83232', 'data', 'dk_parl', 'dkparl_simple_20221216.json') # sti til data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parldata = pd.read_json(file_p, orient = 'records') # indlæs med pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parldata = parldata.explode('items') # omdan lister af tekster til rækker - en række per tekst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parldata = parldata.dropna() # fjerner missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parldata['date'] = pd.to_datetime(parldata['DateOfSitting']) # konverter datoformat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parldata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parldata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parldata2010 = parldata.loc[parldata['date'].dt.year == 2010, :] # udvælger data fra 2010"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tokenize med `spaCy`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parltexts = parldata2010['items'].str.lower() # liste af tekster i lower-case\n",
    "\n",
    "tokenized = [] # tom liste af pre-processed tekst\n",
    "\n",
    "nlp_tokenize = spacy.load('da_core_news_md', enable=['tokenizer']) # indlæser sprogmodel på ny men bruger kun tokenizer\n",
    "\n",
    "# looper igennem hver tekst og tokenizer - nlp.pipe behandler tekster i batches.\n",
    "# tqdm er blot for at få en progress bar - skal bruge en \"total\" (tekster i alt) for at udregne resterende tid.\n",
    "\n",
    "for doc in tqdm(nlp_tokenize.pipe(parltexts), total=len(parltexts)): \n",
    "    # liste til tokens i enkelt tekst\n",
    "    text_tokens = []\n",
    "    \n",
    "    # loop igennem tokens i doc-objekt\n",
    "    for token in doc:\n",
    "        text_tokens.append(token.text) # tilføj token til token-liste\n",
    "\n",
    "    # tilføj tekst tokens til samlede liste\n",
    "    tokenized.append(text_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Træn model med `gensim`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(sentences=tokenized,  # input data\n",
    "                 vector_size=50,       # antal dimensioner (størrelse på embedding)\n",
    "                 window=5,             # kontekstvindue (hvor mange ord skal tælles som del af kontekst?)\n",
    "                 sg=1,                 # cbow eller skip-gram (cbow=0, sg=1)\n",
    "                 negative=5,           # antal negative samples den skal danne for hvert tekststykke (jo flere, jo længere beregningstid)\n",
    "                 min_count=3,          # minimumsgrænse for hvor mange gange ordet skal optræde\n",
    "                 workers=8)            # antal CPU kerner (tjek din maskine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mest lignende ord**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.most_similar('danmark', topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.most_similar('danskerne', topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.most_similar('eu', topn=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sammenlign ord**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.similarity('afghanistan', 'irak')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2 (default, Feb 28 2021, 17:03:44) \n[GCC 10.2.1 20210110]"
  },
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
