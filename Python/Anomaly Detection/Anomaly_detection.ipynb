{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "97df0599-7708-43ac-a36a-ba701793603d",
      "metadata": {
        "id": "97df0599-7708-43ac-a36a-ba701793603d"
      },
      "source": [
        "# Anomaly Detection"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ab574415-b3ef-4c3a-9161-7ccb3dbe409a",
      "metadata": {
        "id": "ab574415-b3ef-4c3a-9161-7ccb3dbe409a"
      },
      "source": [
        "In this notebook, we will explore some basic and advanced anomaly detection techniques. Anomalous data points are those which are significantly different from the rest of the data.\n",
        "\n",
        "Below you will see some examples of anomaly detection techniques that could be used to find anomalies in different data scenarios.\n",
        "\n",
        "We will begin with some basic methods that we can use to detect anomalies. Those techniques will focus on descriptive statistics and visualizations of the distribution of the data. For most anomaly detection problems, those simple methods will be insufficient, but it is always a good strategy to begin with simple exploratory methods."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ddaf80cf-d4e5-40d3-b3cd-8f12f553e3b1",
      "metadata": {
        "id": "ddaf80cf-d4e5-40d3-b3cd-8f12f553e3b1"
      },
      "outputs": [],
      "source": [
        "!pip install pyod\n",
        "!pip install combo\n",
        "!pip install pytrends\n",
        "!pip install statsmodels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ec8ba14-3b8a-4b98-a9fd-0cc0ff5ed209",
      "metadata": {
        "id": "4ec8ba14-3b8a-4b98-a9fd-0cc0ff5ed209"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from pyod.utils.data import generate_data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c09ab0fd-d6e0-4396-9003-5928b2c8a07e",
      "metadata": {
        "id": "c09ab0fd-d6e0-4396-9003-5928b2c8a07e"
      },
      "source": [
        "We will first generate data. We are going to introduce some outliers into the data, so that we know the outliers and their properties. Then we are going to use some simple techniques that may help us finding the outliers in the data. Below we will specify the parameters of the data generating function.\n",
        "\n",
        "The **contamination** parameter determines the proportion of outlier data points. The **n_features** parameter determines the number of features (columns) of the dataset. Later we will also need to divide the data sample into training and test datasets. But at this stage, we will use the full data sample."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8cf8f51-461f-49a6-b766-7dbe3d1f6102",
      "metadata": {
        "id": "c8cf8f51-461f-49a6-b766-7dbe3d1f6102"
      },
      "outputs": [],
      "source": [
        "contamination = 0.05 # share of outliers, here 5%\n",
        "n_features = 1 # univariate\n",
        "n_train = 500\n",
        "n_test = 500\n",
        "\n",
        "X_train, X_test, y_train, y_test = generate_data(\n",
        "    n_train = n_train,\n",
        "    n_test = n_test,\n",
        "    n_features = n_features,\n",
        "    contamination = contamination,\n",
        "    random_state = 123\n",
        ")\n",
        "\n",
        "X_train_pd = pd.DataFrame(X_train)\n",
        "X_train_pd.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ef828a45-2f98-4abe-9cef-61e2ed273788",
      "metadata": {
        "tags": [],
        "id": "ef828a45-2f98-4abe-9cef-61e2ed273788"
      },
      "source": [
        "#### Histogram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48529534-e653-4504-94fb-7ceac31376a9",
      "metadata": {
        "id": "48529534-e653-4504-94fb-7ceac31376a9"
      },
      "outputs": [],
      "source": [
        "plt.hist(X_train_pd[0], bins = 'auto') # bin size definition is important to detect outliers. Small bin sizes make outliers score higher, and vise versa. Auto is usually the best option.\n",
        "plt.title(\"X\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f911e3eb-2ac2-4e4e-a65f-0f5557e8b125",
      "metadata": {
        "tags": [],
        "id": "f911e3eb-2ac2-4e4e-a65f-0f5557e8b125"
      },
      "source": [
        "#### Boxplot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "663f26c9-92b6-4cdb-800b-a86719efe319",
      "metadata": {
        "id": "663f26c9-92b6-4cdb-800b-a86719efe319"
      },
      "outputs": [],
      "source": [
        "plt.boxplot(X_train_pd[0], vert = False)\n",
        "plt.show()\n",
        "# Not a very reliable option, if there are too many outliers. Widely used in statistical approaches."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8935ad18-ddeb-4c73-a649-281871d28a20",
      "metadata": {
        "id": "8935ad18-ddeb-4c73-a649-281871d28a20"
      },
      "source": [
        "# **Histogram-based Outlier Score**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8aed88b-6356-4b9a-83ef-ca1a08711100",
      "metadata": {
        "id": "e8aed88b-6356-4b9a-83ef-ca1a08711100"
      },
      "outputs": [],
      "source": [
        "This time we are going to generate multivariate data and use a more sophisticated histogram-based method to detect anomalies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b84b985-b498-46b3-9526-70de06ac4538",
      "metadata": {
        "id": "1b84b985-b498-46b3-9526-70de06ac4538"
      },
      "outputs": [],
      "source": [
        "contamination = 0.05\n",
        "n_features = 5 #multivariate\n",
        "n_train = 500\n",
        "n_test = 500\n",
        "\n",
        "X_train, X_test, y_train, y_test = generate_data(\n",
        "    n_train = n_train,\n",
        "    n_test = n_test,\n",
        "    n_features = n_features,\n",
        "    contamination = contamination,\n",
        "    random_state = 1234\n",
        ")\n",
        "\n",
        "X_train_pd = pd.DataFrame(X_train)\n",
        "X_train_pd.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cd40712c-2f72-402b-87b6-97d4825fc4a1",
      "metadata": {
        "id": "cd40712c-2f72-402b-87b6-97d4825fc4a1"
      },
      "source": [
        "Datapoints can have different outlier score across different dimensions, i.e. it can be seen as an outlier within one dimension, but not others.\n",
        "Whether a datapoint is an outlier also depends on the domain ones data is from"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e83bce0f-31ad-442c-b50f-f0004881e909",
      "metadata": {
        "id": "e83bce0f-31ad-442c-b50f-f0004881e909"
      },
      "outputs": [],
      "source": [
        "plt.scatter(X_train_pd[0], X_train_pd[1], c=y_train, alpha=0.8)\n",
        "plt.title('Scatter plot')\n",
        "plt.xlabel('x0')\n",
        "plt.ylabel('x1')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e32a7b07-7def-4e65-aac6-955c7dc45ecf",
      "metadata": {
        "id": "e32a7b07-7def-4e65-aac6-955c7dc45ecf"
      },
      "source": [
        "**Train the model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1bacd277-3576-496a-8fab-64a8c03d1f6b",
      "metadata": {
        "id": "1bacd277-3576-496a-8fab-64a8c03d1f6b"
      },
      "outputs": [],
      "source": [
        "from pyod.models.hbos import HBOS\n",
        "n_bins = 50\n",
        "hbos = HBOS(n_bins=n_bins,contamination=0.05)\n",
        "hbos.fit(X_train)\n",
        "\n",
        "# Training data\n",
        "y_train_scores = hbos.decision_function(X_train)\n",
        "y_train_pred = hbos.predict(X_train)\n",
        "\n",
        "# Test data\n",
        "y_test_scores = hbos.decision_function(X_test)\n",
        "y_test_pred = hbos.predict(X_test) # outlier labels (0 or 1)\n",
        "\n",
        "# Threshold for the defined comtanimation rate\n",
        "print(\"The threshold for the defined contamination rate:\" , hbos.threshold_)\n",
        "\n",
        "def count_stat(vector):\n",
        "    # Because it is '0' and '1', we can run a count statistic.\n",
        "    unique, counts = np.unique(vector, return_counts=True)\n",
        "    return dict(zip(unique, counts))\n",
        "\n",
        "print(\"The training data:\", count_stat(y_train_pred))\n",
        "print(\"The training data:\", count_stat(y_test_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "200f816f-a286-4f07-8f06-b7f2b5ce503d",
      "metadata": {
        "id": "200f816f-a286-4f07-8f06-b7f2b5ce503d"
      },
      "outputs": [],
      "source": [
        "plt.hist(y_train_scores, bins='auto') # arguments are passed to np.histogram\n",
        "plt.title(\"Outlier score\")\n",
        "plt.show()\n",
        "# Observations to the right of the threshold are seen as outliers. In this case the model chose the threshold so that 5% of the data would be to the right of it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f821690-16de-4aeb-ae46-09401314ccdc",
      "metadata": {
        "id": "9f821690-16de-4aeb-ae46-09401314ccdc"
      },
      "outputs": [],
      "source": [
        "threshold = hbos.threshold_ # Or other value from the above histogram\n",
        "\n",
        "def descriptive_stat_threshold(df,pred_score, threshold):\n",
        "    # Let's see how many '0's and '1's.\n",
        "    df = pd.DataFrame(df)\n",
        "    df['Anomaly_Score'] = pred_score\n",
        "    df['Group'] = np.where(df['Anomaly_Score']< threshold, 'Normal', 'Outlier')\n",
        "\n",
        "    # Now let's show the summary statistics:\n",
        "    cnt = df.groupby('Group')['Anomaly_Score'].count().reset_index().rename(columns={'Anomaly_Score':'Count'})\n",
        "    cnt['Count %'] = (cnt['Count'] / cnt['Count'].sum()) * 100 # The count and count %\n",
        "    stat = df.groupby('Group').mean().round(2).reset_index() # The avg.\n",
        "    stat = cnt.merge(stat, left_on='Group',right_on='Group') # Put the count and the avg. together\n",
        "    return (stat)\n",
        "\n",
        "descriptive_stat_threshold(X_train,y_train_scores, threshold)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9b10c42-1130-4bce-8d95-c537202422b2",
      "metadata": {
        "id": "f9b10c42-1130-4bce-8d95-c537202422b2"
      },
      "outputs": [],
      "source": [
        "descriptive_stat_threshold(X_test,y_test_scores, threshold)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55b08e9c-0da2-4751-9b60-6b7699ee183f",
      "metadata": {
        "id": "55b08e9c-0da2-4751-9b60-6b7699ee183f"
      },
      "outputs": [],
      "source": [
        "def confusion_matrix(actual,score, threshold):\n",
        "    Actual_pred = pd.DataFrame({'Actual': actual, 'Pred': score})\n",
        "    Actual_pred['Pred'] = np.where(Actual_pred['Pred']<=threshold,0,1)\n",
        "    cm = pd.crosstab(Actual_pred['Actual'],Actual_pred['Pred'])\n",
        "    return (cm)\n",
        "confusion_matrix(y_train,y_train_scores,threshold)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd55126a-bcde-4a54-9a3f-bc68a350d6eb",
      "metadata": {
        "tags": [],
        "id": "fd55126a-bcde-4a54-9a3f-bc68a350d6eb"
      },
      "outputs": [],
      "source": [
        "confusion_matrix(y_test,y_test_scores,threshold)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "818c1827-817b-468d-99f1-192e633cbbcc",
      "metadata": {
        "id": "818c1827-817b-468d-99f1-192e633cbbcc"
      },
      "outputs": [],
      "source": [
        "from pyod.models.combination import aom, moa, average, maximization\n",
        "from pyod.utils.utility import standardizer\n",
        "from pyod.models.hbos import HBOS\n",
        "\n",
        "# Standardize data\n",
        "X_train_norm, X_test_norm = standardizer(X_train, X_test)\n",
        "\n",
        "# Test a range of binning\n",
        "k_list = [5, 10, 15, 20, 25, 30, 50, 60, 75, 100] # Specify a list of bin sizes\n",
        "n_clf = len(k_list) # calculate based on each bin size. By averaging across different bin sizes the predictive quality can be improved.\n",
        "# Just prepare data frames so we can store the model results\n",
        "train_scores = np.zeros([X_train.shape[0], n_clf])\n",
        "test_scores = np.zeros([X_test.shape[0], n_clf])\n",
        "# Modeling\n",
        "for i in range(n_clf):\n",
        "    k = k_list[i]\n",
        "    hbos = HBOS(n_bins=n_bins)\n",
        "    hbos.fit(X_train_norm)\n",
        "    # Store the results in each column:\n",
        "    train_scores[:, i] = hbos.decision_function(X_train_norm)\n",
        "    test_scores[:, i] = hbos.decision_function(X_test_norm)\n",
        "    thresholds[:, i] = hbos.threshold_\n",
        "# Decision scores have to be normalized before combination\n",
        "train_scores_norm, test_scores_norm = standardizer(train_scores,test_scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc6eb298-f6a8-4840-a6ef-692f45029b44",
      "metadata": {
        "id": "fc6eb298-f6a8-4840-a6ef-692f45029b44"
      },
      "outputs": [],
      "source": [
        "# Combination by average\n",
        "# The test_scores_norm is 500 x 10. The \"average\" function will take the average of the 10 columns. The result \"y_by_average\" is a single column:\n",
        "y_train_by_average = average(train_scores_norm)\n",
        "y_test_by_average = average(test_scores_norm)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.hist(y_train_by_average, bins='auto') # arguments are passed to np.histogram\n",
        "plt.title(\"Combination by average\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0fdc3374-c3c5-44e9-9d68-442f5b0e0e1f",
      "metadata": {
        "id": "0fdc3374-c3c5-44e9-9d68-442f5b0e0e1f"
      },
      "source": [
        "# **Isolation Forest**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2865afc4-c554-4697-8543-e37e447c2be2",
      "metadata": {
        "id": "2865afc4-c554-4697-8543-e37e447c2be2"
      },
      "outputs": [],
      "source": [
        "from pyod.models.iforest import IForest\n",
        "isft = IForest(contamination=0.05, max_samples=40, behaviour='new')\n",
        "isft.fit(X_train)\n",
        "\n",
        "# Training data\n",
        "y_train_scores = isft.decision_function(X_train)\n",
        "y_train_pred = isft.predict(X_train)\n",
        "\n",
        "# Test data\n",
        "y_test_scores = isft.decision_function(X_test)\n",
        "y_test_pred = isft.predict(X_test) # outlier labels (0 or 1)\n",
        "\n",
        "# Threshold for the defined comtanimation rate\n",
        "print(\"The threshold for the defined contamination rate:\" , isft.threshold_)\n",
        "\n",
        "def count_stat(vector):\n",
        "    # Because it is '0' and '1', we can run a count statistic.\n",
        "    unique, counts = np.unique(vector, return_counts=True)\n",
        "    return dict(zip(unique, counts))\n",
        "\n",
        "print(\"The training data:\", count_stat(y_train_pred))\n",
        "print(\"The training data:\", count_stat(y_test_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e08f43ee-c085-4f0a-8308-8b40d2d244c2",
      "metadata": {
        "id": "e08f43ee-c085-4f0a-8308-8b40d2d244c2"
      },
      "outputs": [],
      "source": [
        "isft.get_params()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a453c299-5fc0-403b-9a55-93de5df6bd62",
      "metadata": {
        "id": "a453c299-5fc0-403b-9a55-93de5df6bd62"
      },
      "outputs": [],
      "source": [
        "isft_vi = isft.feature_importances_\n",
        "isft_vi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e14503f6-b5c6-406e-883b-3fed1273a3d6",
      "metadata": {
        "id": "e14503f6-b5c6-406e-883b-3fed1273a3d6"
      },
      "outputs": [],
      "source": [
        "plt.hist(y_train_scores, bins='auto') # arguments are passed to np.histogram\n",
        "plt.title(\"Outlier score\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c894011-6d97-48c6-af4a-08eff266a975",
      "metadata": {
        "id": "7c894011-6d97-48c6-af4a-08eff266a975"
      },
      "outputs": [],
      "source": [
        "threshold = isft.threshold_ # Or other value from the above histogram\n",
        "\n",
        "def descriptive_stat_threshold(df,pred_score, threshold):\n",
        "    # Let's see how many '0's and '1's.\n",
        "    df = pd.DataFrame(df)\n",
        "    df['Anomaly_Score'] = pred_score\n",
        "    df['Group'] = np.where(df['Anomaly_Score']< threshold, 'Normal', 'Outlier')\n",
        "\n",
        "    # Now let's show the summary statistics:\n",
        "    cnt = df.groupby('Group')['Anomaly_Score'].count().reset_index().rename(columns={'Anomaly_Score':'Count'})\n",
        "    cnt['Count %'] = (cnt['Count'] / cnt['Count'].sum()) * 100 # The count and count %\n",
        "    stat = df.groupby('Group').mean().round(2).reset_index() # The avg.\n",
        "    stat = cnt.merge(stat, left_on='Group',right_on='Group') # Put the count and the avg. together\n",
        "    return (stat)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4ac5b7d-09eb-46c8-86e7-d429e16080fa",
      "metadata": {
        "id": "e4ac5b7d-09eb-46c8-86e7-d429e16080fa"
      },
      "outputs": [],
      "source": [
        "descriptive_stat_threshold(X_train,y_train_scores, threshold)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41262faa-419a-47ea-87ff-c793022b9748",
      "metadata": {
        "id": "41262faa-419a-47ea-87ff-c793022b9748"
      },
      "outputs": [],
      "source": [
        "descriptive_stat_threshold(X_test,y_test_scores, threshold)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3230e410-d11b-4be1-8e1b-e38bc86baaae",
      "metadata": {
        "id": "3230e410-d11b-4be1-8e1b-e38bc86baaae"
      },
      "outputs": [],
      "source": [
        "confusion_matrix(y_train,y_train_scores,threshold)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "96a1ac6c-bbce-4059-ba55-f7df9592fddb",
      "metadata": {
        "id": "96a1ac6c-bbce-4059-ba55-f7df9592fddb"
      },
      "outputs": [],
      "source": [
        "confusion_matrix(y_test,y_test_scores,threshold)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18e0c7b4-1c50-4939-82d2-dc4dacd1ba14",
      "metadata": {
        "id": "18e0c7b4-1c50-4939-82d2-dc4dacd1ba14"
      },
      "outputs": [],
      "source": [
        "# Standardize data\n",
        "X_train_norm, X_test_norm = standardizer(X_train, X_test)\n",
        "\n",
        "# Test a range of maximum samples\n",
        "k_list = [20, 30, 40, 50, 60]\n",
        "k_list = [100, 200, 300, 400, 500]\n",
        "n_clf = len(k_list)\n",
        "# Just prepare data frames so we can store the model results\n",
        "train_scores = np.zeros([X_train.shape[0], n_clf])\n",
        "test_scores = np.zeros([X_test.shape[0], n_clf])\n",
        "\n",
        "# Modeling\n",
        "for i in range(n_clf):\n",
        "    k = k_list[i]\n",
        "    #isft = IForest(contamination=0.05, max_samples=k)\n",
        "    isft = IForest(contamination=0.05, n_estimators=k)\n",
        "    isft.fit(X_train_norm)\n",
        "\n",
        "    # Store the results in each column:\n",
        "    train_scores[:, i] = isft.decision_function(X_train_norm)\n",
        "    test_scores[:, i] = isft.decision_function(X_test_norm)\n",
        "# Decision scores have to be normalized before combination\n",
        "train_scores_norm, test_scores_norm = standardizer(train_scores,test_scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "820877d9-4c9d-448d-ae33-d62a45a0c0e6",
      "metadata": {
        "id": "820877d9-4c9d-448d-ae33-d62a45a0c0e6"
      },
      "outputs": [],
      "source": [
        "# Combination by average\n",
        "# The test_scores_norm is 500 x 10. The \"average\" function will take the average of the 10 columns. The result \"y_by_average\" is a single column:\n",
        "y_train_by_average = average(train_scores_norm)\n",
        "y_test_by_average = average(test_scores_norm)\n",
        "import matplotlib.pyplot as plt\n",
        "plt.hist(y_train_by_average, bins='auto') # arguments are passed to np.histogram\n",
        "plt.title(\"Combination by average\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06f37387-c025-4e16-b4e5-6cb61b8973b1",
      "metadata": {
        "id": "06f37387-c025-4e16-b4e5-6cb61b8973b1"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 ",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}